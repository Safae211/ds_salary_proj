{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4c9782a-acd2-4de3-bd0d-9ff5e19819fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: selenium in /Users/user/Library/Python/3.9/lib/python/site-packages (4.35.0)\n",
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: pandas in /Users/user/Library/Python/3.9/lib/python/site-packages (2.3.2)\n",
      "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /Users/user/Library/Python/3.9/lib/python/site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
      "Requirement already satisfied: trio~=0.30.0 in /Users/user/Library/Python/3.9/lib/python/site-packages (from selenium) (0.30.0)\n",
      "Requirement already satisfied: trio-websocket~=0.12.2 in /Users/user/Library/Python/3.9/lib/python/site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2025.6.15 in /Users/user/Library/Python/3.9/lib/python/site-packages (from selenium) (2025.8.3)\n",
      "Requirement already satisfied: typing_extensions~=4.14.0 in /Users/user/Library/Python/3.9/lib/python/site-packages (from selenium) (4.14.1)\n",
      "Requirement already satisfied: websocket-client~=1.8.0 in /Users/user/Library/Python/3.9/lib/python/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /Users/user/Library/Python/3.9/lib/python/site-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/user/Library/Python/3.9/lib/python/site-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /Users/user/Library/Python/3.9/lib/python/site-packages (from trio~=0.30.0->selenium) (3.10)\n",
      "Requirement already satisfied: outcome in /Users/user/Library/Python/3.9/lib/python/site-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /Users/user/Library/Python/3.9/lib/python/site-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /Users/user/Library/Python/3.9/lib/python/site-packages (from trio~=0.30.0->selenium) (1.3.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/user/Library/Python/3.9/lib/python/site-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /Users/user/Library/Python/3.9/lib/python/site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: requests in /Users/user/Library/Python/3.9/lib/python/site-packages (from webdriver-manager) (2.32.5)\n",
      "Collecting python-dotenv (from webdriver-manager)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: packaging in /Users/user/Library/Python/3.9/lib/python/site-packages (from webdriver-manager) (25.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/user/Library/Python/3.9/lib/python/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/user/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/user/Library/Python/3.9/lib/python/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/user/Library/Python/3.9/lib/python/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/user/Library/Python/3.9/lib/python/site-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/user/Library/Python/3.9/lib/python/site-packages (from requests->webdriver-manager) (3.4.3)\n",
      "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv, webdriver-manager\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [webdriver-manager]\n",
      "\u001b[1A\u001b[2KSuccessfully installed python-dotenv-1.1.1 webdriver-manager-4.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium webdriver-manager pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9564731b-8e4f-43ac-8dd2-c2a29b7ceef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies first if needed\n",
    "# !pip install selenium webdriver-manager pandas\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, ElementClickInterceptedException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def get_jobs(keyword, num_jobs=10, verbose=True, slp_time=3):\n",
    "    \"\"\"\n",
    "    Scrapes Glassdoor job listings into a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    options = Options()\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    # options.add_argument(\"--headless\")  # uncomment to run in background\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    \n",
    "    # Open Glassdoor job search page\n",
    "    url = f'https://www.glassdoor.com/Job/jobs.htm?sc.keyword=\"{keyword}\"'\n",
    "    print(\"Opening Glassdoor...\")\n",
    "    driver.get(url)\n",
    "    time.sleep(slp_time)\n",
    "    \n",
    "    jobs = []\n",
    "    \n",
    "    while len(jobs) < num_jobs:\n",
    "        time.sleep(slp_time)\n",
    "        \n",
    "        # Close signup pop-up if it appears\n",
    "        try:\n",
    "            popup_close = WebDriverWait(driver, 3).until(\n",
    "                EC.element_to_be_clickable((By.CSS_SELECTOR, 'button[aria-label=\"Close\"]'))\n",
    "            )\n",
    "            popup_close.click()\n",
    "            if verbose:\n",
    "                print(\"Signup popup closed\")\n",
    "        except TimeoutException:\n",
    "            if verbose:\n",
    "                print(\"No signup popup found\")\n",
    "        \n",
    "        # Wait until job cards are visible\n",
    "        try:\n",
    "            job_cards = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'li.react-job-listing'))\n",
    "            )\n",
    "        except TimeoutException:\n",
    "            print(\"No job listings found on this page.\")\n",
    "            break\n",
    "        \n",
    "        for card in job_cards:\n",
    "            if len(jobs) >= num_jobs:\n",
    "                break\n",
    "            try:\n",
    "                card.click()\n",
    "                time.sleep(1)\n",
    "                \n",
    "                # Extract job info\n",
    "                job_title = card.find_element(By.CSS_SELECTOR, 'a[data-test=\"job-link\"]').text\n",
    "                company_name = card.find_element(By.CSS_SELECTOR, 'div[data-test=\"employer-name\"]').text\n",
    "                location = card.find_element(By.CSS_SELECTOR, 'div[data-test=\"location\"]').text\n",
    "                try:\n",
    "                    salary = card.find_element(By.CSS_SELECTOR, 'span[data-test=\"detailSalary\"]').text\n",
    "                except NoSuchElementException:\n",
    "                    salary = None\n",
    "                try:\n",
    "                    rating = card.find_element(By.CSS_SELECTOR, 'span[data-test=\"detailRating\"]').text\n",
    "                except NoSuchElementException:\n",
    "                    rating = None\n",
    "                \n",
    "                jobs.append({\n",
    "                    \"Job Title\": job_title,\n",
    "                    \"Company Name\": company_name,\n",
    "                    \"Location\": location,\n",
    "                    \"Salary\": salary,\n",
    "                    \"Rating\": rating\n",
    "                })\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"Scraped: {job_title} at {company_name}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                if verbose:\n",
    "                    print(\"Error scraping a card:\", e)\n",
    "                continue\n",
    "        \n",
    "        # Go to next page\n",
    "        try:\n",
    "            next_button = driver.find_element(By.CSS_SELECTOR, 'li.next a')\n",
    "            next_button.click()\n",
    "            time.sleep(slp_time)\n",
    "        except NoSuchElementException:\n",
    "            print(\"No more pages or reached scraping limit\")\n",
    "            break\n",
    "    \n",
    "    driver.quit()\n",
    "    print(f\"Scraping finished. Total jobs collected: {len(jobs)}\")\n",
    "    return pd.DataFrame(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6876055e-0d73-414a-9d55-69ca471621aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping finished early. Got 0 jobs.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_jobs(\"data scientist\", 5, True, 5)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72ae7793-1e0a-440e-943e-2831126a2b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scraper...\n",
      "Scraping finished early. Got 0 jobs.\n",
      "Scraper finished.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Starting scraper...\")\n",
    "df = get_jobs(\"data scientist\", 5, True, 5)\n",
    "print(\"Scraper finished.\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9d59ba1-56c3-48b7-b391-83a39a8ee656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping finished early. Got 0 jobs.\n"
     ]
    }
   ],
   "source": [
    "df = get_jobs(\"data scientist\", 3, True, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5aea60f3-ba54-4e2c-8b9d-3efafb899bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening Glassdoor...\n",
      "No signup popup found\n",
      "No job listings found on this page.\n",
      "Scraping finished. Total jobs collected: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Scrape 5 data scientist jobs\n",
    "df = get_jobs(\"data scientist\", num_jobs=5, verbose=True, slp_time=3)\n",
    "\n",
    "# Show first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f83eb06-ebe4-4c19-a4a1-fa4235a8cb2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
